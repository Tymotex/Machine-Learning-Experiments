{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing the following 3-layer network\n",
    "![title](img/chap6_3layer.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights from 0 to 1:\n",
      "[[ 0.49762021 -0.83559291  0.15844297  0.06489488]\n",
      " [ 0.45836711  0.780598    0.81965766  0.04149217]\n",
      " [-0.72932099  0.04604929 -0.73109746  0.17238014]]\n",
      "Weights from 1 to 2:\n",
      "[[ 0.03471422]\n",
      " [ 0.89945896]\n",
      " [ 0.12471945]\n",
      " [-0.0187963 ]]\n",
      "Layer 1's 4 node values are:\n",
      "[-0.         -0.         -0.          0.23727502]\n",
      "Layer 2's output is:\n",
      "[-0.00445989]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# np.random.seed(1)\n",
    "\n",
    "def relu(x):\n",
    "    return (x > 0) * x\n",
    "\n",
    "alpha = 0.2\n",
    "hidden_size = 4\n",
    "\n",
    "streetlights = np.array([[1, 0, 1],\n",
    "                         [0, 1, 1],\n",
    "                         [0, 0, 1],\n",
    "                         [1, 1, 1]])\n",
    "\n",
    "walk_vs_stop = np.array([[1, 1, 0, 0]]).T\n",
    "\n",
    "# Generate weights in a 3x4 matrix\n",
    "weights_0_1 = 2 * np.random.random((3, hidden_size)) - 1\n",
    "# Generate weights in a 4x1 matrix\n",
    "weights_1_2 = 2 * np.random.random((hidden_size, 1)) - 1\n",
    "\n",
    "print(\"Weights from 0 to 1:\")\n",
    "print(weights_0_1)\n",
    "print(\"Weights from 1 to 2:\")\n",
    "print(weights_1_2)\n",
    "\n",
    "layer_0 = streetlights[0]\n",
    "layer_1 = relu(np.dot(layer_0, weights_0_1))\n",
    "\n",
    "\n",
    "print(\"Layer 1's 4 node values are:\")\n",
    "print(layer_1)\n",
    "\n",
    "layer_2 = np.dot(layer_1, weights_1_2)\n",
    "print(\"Layer 2's output is:\")\n",
    "print(layer_2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now, using backpropagation:\n",
    "Try to follow through with the vector operations on paper\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: 0.6342311598444467\n",
      "Error: 0.35838407676317513\n",
      "Error: 0.0830183113303298\n",
      "Error: 0.006467054957103705\n",
      "Error: 0.0003292669000750734\n",
      "Error: 1.5055622665134859e-05\n",
      "[0, 1, 0] has prediction: [0.99592182]\n",
      "[0, 0, 1] has prediction: [0.00263144]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.random.seed(1)\n",
    "\n",
    "def relu(x):\n",
    "    return (x > 0) * x\n",
    "\n",
    "# Derivative of the relu function\n",
    "# Outputs: 1 if positive, or 0 if negative\n",
    "# 1 is the slope of the relu function for positive inputs, 0 is the slope for negative inputs into relu\n",
    "def reluDerivative(x):\n",
    "    return x > 0\n",
    "\n",
    "alpha = 0.2\n",
    "hidden_size = 4\n",
    "\n",
    "streetlights = np.array([[1, 0, 1],\n",
    "                         [0, 1, 1],\n",
    "                         [0, 0, 1],\n",
    "                         [1, 1, 1]])\n",
    "\n",
    "walk_vs_stop = np.array([[1, 1, 0, 0]]).T\n",
    "\n",
    "weights_0_1 = 2 * np.random.random((3, hidden_size)) - 1\n",
    "weights_1_2 = 2 * np.random.random((hidden_size, 1)) - 1\n",
    "\n",
    "for iteration in range(60):\n",
    "    layer_2_error = 0\n",
    "    for i in range(len(streetlights)):\n",
    "        # Note that slicing [i : i + 1] will return a list of the single element at index i\n",
    "        layer_0 = streetlights[i : i + 1]  \n",
    "        # np.dot with matrix operands of sizes: 1x3 . 3x4 will produce a 1x4 result \n",
    "        layer_1 = relu(np.dot(layer_0, weights_0_1))\n",
    "        \n",
    "        # layer_2 is just the single output layer node\n",
    "        layer_2 = np.dot(layer_1, weights_1_2)\n",
    "        \n",
    "        # Mean squared error of layer 2\n",
    "        layer_2_error += np.sum((layer_2 - walk_vs_stop[i:i+1]) ** 2)\n",
    "        layer_2_delta = layer_2 - walk_vs_stop[i : i + 1]\n",
    "        \n",
    "        # Determine layer_1's deltas (one for each of the 4 nodes in layer 1)\n",
    "        # This calculation gives a 'weighting' to how much each weight contributed to the output delta\n",
    "        # of layer_2.\n",
    "        # Since we only want to attribute errors to the nodes of layer_1 whose input value was NOT zero\n",
    "        # we can multiply by reluDerivative which will assign a delta of 0 to the node with input value 0 \n",
    "        layer_1_delta = layer_2_delta.dot(weights_1_2.T) * reluDerivative(layer_1)\n",
    "        # Adjusting the weights of layer1 -> layer2 and layer0 -> layer1\n",
    "        weights_1_2 -= alpha * layer_1.T.dot(layer_2_delta)\n",
    "        weights_0_1 -= alpha * layer_0.T.dot(layer_1_delta)\n",
    "\n",
    "    if(iteration % 10 == 9):\n",
    "        print(\"Error: {}\".format(layer_2_error))\n",
    "\n",
    "# Some simple tests:\n",
    "# Input [0, 1, 0] should be 1\n",
    "layer_0 = [0, 1, 0]  \n",
    "layer_1 = relu(np.dot(layer_0, weights_0_1))\n",
    "layer_2 = np.dot(layer_1, weights_1_2)\n",
    "print(\"{} has prediction: {}\".format(layer_0, layer_2))\n",
    "\n",
    "# Input [0, 0, 1] should be 0\n",
    "layer_0 = [0, 0, 1]  \n",
    "layer_1 = relu(np.dot(layer_0, weights_0_1))\n",
    "layer_2 = np.dot(layer_1, weights_1_2)\n",
    "print(\"{} has prediction: {}\".format(layer_0, layer_2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 'delta' for a node tells us how much we want the output value to that node to change. Consider layer_1: once we know the layer_1 deltas (from layer_2_delta * weights_1_2 * reluDerivative(layer_1)), we know how to adjust the weights in weights_1_2 (simply multiply each node in layer_1's outgoing weight by the input and subtract that value from the current weight). We have reluDerivative(layer_1) because if a certain node value was switched to zero, we can't attribute any error to that node.\n",
    "\n",
    "Backpropagation is about calculating deltas for intermediate layers so that you can perform gradient descent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
