{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overfitting and Reusing Weights:\n",
    "In general, the more parameters/weights, the greater the tendency for the neural network to overfit the training dataset. Overfitting is concerned with the <em>ratio</em> between the <em>number of weights</em> in the model and the <em>number of datapoints</em> it trains on to learn those weights.\n",
    "\n",
    "Regularisation is just one class of techniques used to combat overfitting. Using convolutional layers involves using a small set of weights, offsetting the ratio of weights to number of datapoints.\n",
    "\n",
    "### Convolutional Layers:\n",
    "The most well-known and widespread <em>structure</em> used in neural networks is called a <em>convolution</em>, and when used in a hidden layer, it's called a <em>convolutional layer</em>.\n",
    "\n",
    "- From Wikipedia: 'CNNs take advantage of the hierarchical pattern in data to assemble more complex patterns from smaller, simpler patterns'\n",
    "- Convolutional neural networks are great for image processing\n",
    "- Just like regular layers, convolutional layers will take in input from the previous layer's nodes, operate on it, then pass on the output to the next layer. It applies a convolution operation on the input\n",
    "- We define <em>filters</em> on the convolutional layer, which are just a matrices of values\n",
    "- <em>Convolving</em> is the process of 'sliding' across the input image and sampling a different subsection of the image\n",
    "- As the name suggests, neural networks use <em>linear convolutions</em> over matrix multiplication in convolutional layers\n",
    "\n",
    "\n",
    "<em>Linear layers</em> connect to every node in the previous layer and output to every node in the next layer. Convolutional layers have lots of very small linear layers &mdash; usually fewer than 25 inputs and a single output &mdash; which are used on every input position. Each of these small linear layers are called <em>convolutional kernels</em>. Convolution layers usually consist of multiple convolutional kernels.\n",
    "\n",
    "Below is a $3 \\times 3$ convolutional kernel which will 'sweep' across the first row, pixel-by-pixel, then drop one pixel down and sweep left, pixel-by-pixel, repeating across the entire input.\n",
    "<img src=\"img/convolutional_kernel.png\" style=\"width: 30%;\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolutional Kernels:\n",
    "The following is an example of how a convolutional layer applies its convolutional kernels on the input, gets each kernel's resulting matrices, then summarises it into a <em>single</em> matrix that gets passed onto the next layer.\n",
    "\n",
    "<br>\n",
    "<div>\n",
    "    Suppose this convolutional layer has 4 kernels. Each of them will begin the top left corner, taking a $3 \\times 3$ matrix sample of the input at that point, then perform SOMETHING to obtain a single value. This single value gets stored in a result matrix.\n",
    "    <img src=\"img/convolutional_kernel_step1.png\" style=\"width: 25%;\">\n",
    "</div>\n",
    "<div>\n",
    "    After sweeping through all possible $3 \\times 3$ sample matrices, the resulting matrix will be $6 \\times 6$. The resulting matrices each kernel produced will be combined to a final matrix that gets passed along to the next layer. We can do this by summing them together (sum pooling), averaging them (mean pooling) or taking the max (max pooling).   \n",
    "    <img src=\"img/convolutional_kernel_step2.png\" style=\"width: 25%;\">\n",
    "</div>\n",
    "<div>\n",
    "    This is the final matrix produced by this convolutional layer when max pooling is used to combine the $6 \\times 6$ matrices produced by the kernels. \n",
    "    <img src=\"img/convolutional_kernel_step3.png\" style=\"width: 20%;\">\n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### An Implementation of Convolutional Layers in the MNIST Digit Classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "from keras.datasets import mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "images = x_train[0 : 1000].reshape(1000, 28 * 28) / 255\n",
    "labels = y_train[0 : 1000]\n",
    "test_images = x_test.reshape(len(x_test), 28 * 28) / 255\n",
    "\n",
    "one_hot_labels = np.zeros((len(labels), 10))\n",
    "for i, eachLabel in enumerate(labels):\n",
    "    one_hot_labels[i][eachLabel] = 1\n",
    "labels = one_hot_labels\n",
    "\n",
    "test_labels = np.zeros((len(y_test), 10))\n",
    "for i, eachLabel in enumerate(y_test):\n",
    "    test_labels[i][eachLabel] = 1\n",
    "\n",
    "alpha = 2\n",
    "iterations = 300\n",
    "pixels_per_image, num_labels = (784, 10)\n",
    "batch_size = 128\n",
    "\n",
    "input_rows, input_cols = (28, 28)\n",
    "kernel_rows, kernel_cols = (3, 3)\n",
    "num_kernels = 16\n",
    "\n",
    "hidden_size = ((input_rows - kernel_rows) * (input_cols - kernel_cols)) * num_kernels\n",
    "\n",
    "np.random.seed(1)\n",
    "kernels = 0.02 * np.random.random((kernel_rows * kernel_cols, num_kernels)) - 0.01\n",
    "weights_1_2 = 0.2 * np.random.random((hidden_size, num_labels)) - 0.1\n",
    "\n",
    "def tanh(x):\n",
    "    return np.tanh(x)\n",
    "\n",
    "def tanhDerivative(x):\n",
    "    return 1 - x ** 2\n",
    "\n",
    "def softmax(x):\n",
    "    tmp = np.exp(x)\n",
    "    return tmp / np.sum(tmp, axis=1, keepdims=True)\n",
    "\n",
    "# Selects a subsection of a batch of images\n",
    "def get_image_section(layer,row_from, row_to, col_from, col_to):\n",
    "    section = layer[:,row_from:row_to,col_from:col_to]\n",
    "    return section.reshape(-1,1,row_to-row_from, col_to-col_from)\n",
    "\n",
    "for iteration in range(iterations):\n",
    "    correct_count = 0\n",
    "    for i in range(int(len(images) / batch_size)):\n",
    "        batch_start = i * batch_size\n",
    "        batch_end = (i + 1) * batch_size\n",
    "        curr_batch = images[batch_start : batch_end]\n",
    "        \n",
    "        # Layer_0 is a 2D array with dimensions 128 * 784\n",
    "        layer_0 = curr_batch\n",
    "        # Layer_0 is now a 3D array with dimensions 128 x 28 x 28: 28 sheets of 128 x 28 matrices\n",
    "        # so each input image is represented as a 28*28 grid rather than a 1*784 sequence\n",
    "        layer_0 = layer_0.reshape(layer_0.shape[0], 28, 28)\n",
    "        \n",
    "        # Getting ALL the subsections of the input images in the batch of 128 images \n",
    "        sects = []\n",
    "        for row_start in range(layer_0.shape[1] - kernel_rows):        # Ranges from 0 to (28 - 3)\n",
    "            for col_start in range(layer_0.shape[2] - kernel_cols):    # Ranges from 0 to (28 - 3)\n",
    "                # For each 28*28 image, there will exist 25*25 subsections of size 3*3\n",
    "                curr_section = get_image_section(layer_0,\n",
    "                                                 row_start,\n",
    "                                                 row_start + kernel_rows,\n",
    "                                                 col_start,\n",
    "                                                 col_start + kernel_cols)\n",
    "                sects.append(curr_section)\n",
    "        \n",
    "        # Joining all subsections into a single array of subsections\n",
    "        expanded_input = np.concatenate(sects, axis=1)\n",
    "        es = expanded_input.shape\n",
    "        # flattened_input has dimensions 80000 x 9, representing each 9-length subsection \n",
    "        # extracted from all 128 images\n",
    "        flattened_input = expanded_input.reshape(es[0] * es[1], -1)\n",
    "        \n",
    "        kernel_output = flattened_input.dot(kernels)\n",
    "        # Layer_1 has dimensions 128 x 10000\n",
    "        layer_1 = tanh(kernel_output.reshape(es[0], -1))\n",
    "        dropout_mask = np.random.randint(2, size=layer_1.shape)\n",
    "        layer_1 *= dropout_mask * 2\n",
    "        layer_2 = softmax(np.dot(layer_1, weights_1_2))\n",
    "        \n",
    "        for j in range(batch_size):\n",
    "            label_set = labels[batch_start + j : batch_start + j + 1]\n",
    "            correct_count += int(np.argmax(layer_2[j : j + 1]) == np.argmax(label_set))\n",
    "        \n",
    "        layer_2_delta = (labels[batch_start : batch_end] - layer_2) / (batch_size * layer_2.shape[0])\n",
    "        layer_1_delta = layer_2_delta.dot(weights_1_2.T) * tanhDerivative(layer_1)\n",
    "        layer_1_delta *= dropout_mask\n",
    "        weights_1_2 += alpha * layer_1.T.dot(layer_2_delta)\n",
    "        \n",
    "        layer_1_reshape_1D = layer_1_delta.reshape(kernel_output.shape)\n",
    "        k_update = flattened_input.T.dot(layer_1_reshape_1D)\n",
    "        kernels -= alpha * k_update\n",
    "        \n",
    "    test_correct_count = 0\n",
    "    for i in range(len(test_images)):\n",
    "        layer_0 = test_images[i:i+1]\n",
    "        layer_0 = layer_0.reshape(layer_0.shape[0],28,28)\n",
    "        \n",
    "        sects = list()\n",
    "        for row_start in range(layer_0.shape[1] - kernel_rows):\n",
    "            for col_start in range(layer_0.shape[2] - kernel_cols):\n",
    "                sect = get_image_section(layer_0,\n",
    "                                         row_start,\n",
    "                                         row_start + kernel_rows,\n",
    "                                         col_start,\n",
    "                                         col_start + kernel_cols)\n",
    "                sects.append(sect)\n",
    "    \n",
    "        expanded_input = np.concatenate(sects,axis=1)\n",
    "        es = expanded_input.shape\n",
    "        flattened_input = expanded_input.reshape(es[0] * es[1], -1)\n",
    "        kernel_output = flattened_input.dot(kernels)\n",
    "        layer_1 = tanh(kernel_output.reshape(es[0],-1))\n",
    "        layer_2 = np.dot(layer_1, weights_1_2)\n",
    "        test_correct_count += int(np.argmax(layer_2) == np.argmax(test_labels[i:i+1]))\n",
    "    \n",
    "    if(iteration % 1 == 0):\n",
    "        sys.stdout.write(\"\\n\" + \\\n",
    "                         \"I:\" + str(iteration) + \\\n",
    "                         \" Test-Acc:\"+str(test_correct_count / float(len(test_images))) + \\\n",
    "                         \" Train-Acc:\" + str(correct_count / float(len(images))))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Some Numpy Array Examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Original 3D Array (3 x 3 x 3) =====\n",
      "[[[ 1  2  3]\n",
      "  [ 4  5  6]\n",
      "  [ 7  8  9]]\n",
      "\n",
      " [[10 11 12]\n",
      "  [13 14 15]\n",
      "  [16 17 18]]\n",
      "\n",
      " [[19 20 21]\n",
      "  [22 23 24]\n",
      "  [25 26 27]]]\n",
      "Shape: (3, 3, 3)\n",
      "\n",
      "===== Transposed 3D Array (3 x 3 x 3) =====\n",
      "[[[ 1 10 19]\n",
      "  [ 4 13 22]\n",
      "  [ 7 16 25]]\n",
      "\n",
      " [[ 2 11 20]\n",
      "  [ 5 14 23]\n",
      "  [ 8 17 26]]\n",
      "\n",
      " [[ 3 12 21]\n",
      "  [ 6 15 24]\n",
      "  [ 9 18 27]]]\n",
      "Shape: (3, 3, 3)\n",
      "\n",
      "===== Reshaped to a single 1D row (1 x 27) =====\n",
      "[[ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n",
      "  25 26 27]]\n",
      "Shape: (1, 27)\n",
      "\n",
      "===== Reshaped to a 2D array (3 x 9) =====\n",
      "[[ 1  2  3  4  5  6  7  8  9]\n",
      " [10 11 12 13 14 15 16 17 18]\n",
      " [19 20 21 22 23 24 25 26 27]]\n",
      "Shape: (3, 9)\n",
      "\n",
      "===== Concatenation =====\n",
      "[[[ 1  2  3]\n",
      "  [ 4  5  6]\n",
      "  [ 7  8  9]]\n",
      "\n",
      " [[10 11 12]\n",
      "  [13 14 15]\n",
      "  [16 17 18]]\n",
      "\n",
      " [[19 20 21]\n",
      "  [22 23 24]\n",
      "  [25 26 27]]\n",
      "\n",
      " [[ 1  2  3]\n",
      "  [ 4  5  6]\n",
      "  [ 7  8  9]]\n",
      "\n",
      " [[10 11 12]\n",
      "  [13 14 15]\n",
      "  [16 17 18]]\n",
      "\n",
      " [[19 20 21]\n",
      "  [22 23 24]\n",
      "  [25 26 27]]]\n",
      "Shape: (6, 3, 3)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "myArr = np.array(\n",
    "    [\n",
    "        [\n",
    "            [\n",
    "                1, 2, 3\n",
    "            ],\n",
    "            [\n",
    "                4, 5, 6\n",
    "            ], \n",
    "            [\n",
    "                7, 8, 9\n",
    "            ]\n",
    "        ],\n",
    "        [\n",
    "            [\n",
    "                10, 11, 12\n",
    "            ],\n",
    "            [\n",
    "                13, 14, 15\n",
    "            ], \n",
    "            [\n",
    "                16, 17, 18\n",
    "            ]\n",
    "        ],\n",
    "        [\n",
    "            [\n",
    "                19, 20, 21\n",
    "            ],\n",
    "            [\n",
    "                22, 23, 24\n",
    "            ], \n",
    "            [\n",
    "                25, 26, 27\n",
    "            ]\n",
    "        ]\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(\"===== Original 3D Array (3 x 3 x 3) =====\")\n",
    "print(myArr)\n",
    "print(\"Shape: {}\\n\".format(myArr.shape))\n",
    "print(\"===== Transposed 3D Array (3 x 3 x 3) =====\")\n",
    "transpose = myArr.T\n",
    "print(transpose)\n",
    "print(\"Shape: {}\\n\".format(transpose.shape))\n",
    "\n",
    "print(\"===== Reshaped to a single 1D row (1 x 27) =====\")\n",
    "reshapedMatrix = myArr.reshape(1, -1)\n",
    "print(reshapedMatrix)  # The -1 means 'unknown length' which lets numpy figure out the valid column number\n",
    "print(\"Shape: {}\\n\".format(reshapedMatrix.shape))\n",
    "print(\"===== Reshaped to a 2D array (3 x 9) =====\")\n",
    "reshapedMatrix = myArr.reshape(3, -1)\n",
    "print(reshapedMatrix)\n",
    "print(\"Shape: {}\\n\".format(reshapedMatrix.shape))\n",
    "\n",
    "print(\"===== Concatenation =====\")\n",
    "concatenated = np.concatenate([myArr, myArr])\n",
    "print(concatenated)\n",
    "print(\"Shape: {}\\n\".format(concatenated.shape))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
