{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/cnn-sequence.png\" width=\"100%\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/convolutional-network-components.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For regular neural networks, an input layer is fed through through a series of hidden layers until reaching the output layer, with every layer being fully connected.\n",
    "\n",
    "With convolutional neural networks, all layers have 3 dimensions. Neurons in one layer are not fully connected to the neurons in the next layer.\n",
    "- Each layer of a convolutional neural network maps a 3D input 'volume' to a 3D output 'volume' of activations.\n",
    "- CNNs have 2 components: the feature extraction part and the classification part (consisting of fully connected layers you'd see for regular networks).\n",
    "    - Feature extraction: passing the input image through a series of convolution, activation and pooling operations\n",
    "    - Classification: based on the extracted features, assigns probabilities to each class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolution Layers:\n",
    "The most well-known and widespread structure used in neural networks is called a convolution, and when used in a hidden layer, it's called a convolutional layer. The development of convolutional layers and the reusing of weights is one of the most important innovations in deep learning.\n",
    "- Just like regular hidden layers in a network, convolutional layers will take in input from the previous layer's nodes, operate on it, then pass on the output to the next layer. It uses *linear convolutions* over *matrix multiplication* on the input\n",
    "- Convolutions revolve around 'reusing a piece of intelligence' in multiple places\n",
    "- Convolving is the process of 'sliding' across the input image and sampling a different subsection of the image\n",
    "- Convolutional layers can be stacked &mdash; this allows for hierarchical decomposition of the input "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td>            \n",
    "            <img src=\"images/convolving-3d.gif\">\n",
    "        </td>\n",
    "        <td>\n",
    "            <img src=\"images/convolving-compute.gif\">\n",
    "        </td>\n",
    "    <tr>\n",
    "</table>\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td>\n",
    "            <img src=\"images/convolution-mapping.png\">\n",
    "        </td>\n",
    "        <td>\n",
    "            <img src=\"images/convolutional-layer-size.png\">\n",
    "        </td>\n",
    "    <tr>\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- *Convolutional filter/kernel* &mdash; a small 3D matrix that used to scan across subsections of the image, computing convolutions and producing a *feature map*\n",
    "    - Also called a 'feature detector'\n",
    "    - *Receptive field* &mdash; the area of the filter\n",
    "    - With RGB images, the kernel will have a 3rd dimension for scanning over each colour channel\n",
    "    - Several different filters can be used to generate different feature maps, all of which are put together as the final output of a convolution layer\n",
    "    <img src=\"images/convolutional-filters-visualised.png\" width=\"50%\">\n",
    "    <strong><p style=\"text-align: center;\">Weights of the convolutional filters visualised</p></strong>\n",
    "    <strong><p style=\"text-align: center;\">Some filters detect lines at certain angles, others detect colour gradients, etc.</p></strong>\n",
    "\n",
    "    \n",
    "- *Stride* &mdash; how far of a jump the kernel or pooling matrix takes after each convolution\n",
    "\n",
    "- *Feature map* or *activation map* &mdash; the output activations for a given filter\n",
    "\n",
    "- *Padding* &mdash; adding layers of zero-value pixels to surround the input, thereby allowing the sliding filter to go beyond the normal image boundaries. This applies to pooling filters as well\n",
    "\n",
    "    - Often used to make the convolutional layer have the same dimension as the input\n",
    "    - Number of outputs in the convolutional layer: $n_{out}=\\big[ \\frac{n_{in}+2p-k}{s} \\big] + 1$ \n",
    "        - Where $n_{in}$ is the number of inputs (pixels), $k$ is the kernel size, $p$ is the padding size, $s$ is the stride size\n",
    "\n",
    "\n",
    "Kernel size, number of kernels, stride and padding are all hyperparameters that we need to decide on.\n",
    "\n",
    "<img src=\"images/convolving-demo.gif\" width=\"75%\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convolution:\n",
    "The convolution operation involves taking the elementwise product of the kernel and the current input elements it's scanning, then summing those values to a single scalar.\n",
    "\n",
    "The combination of two functions to produce a third function - merging two sets of information.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pooling Layer:\n",
    "After the convolutional layer, we may pass the output through a *pooling layer*.\n",
    "\n",
    "The purpose of pooling is to reduce the dimensionality and reduce the number of parameters and computation &mdash; combating overfitting and long training times.\n",
    "- The most frequently used type of pooling is *max pooling* which extracts the max value in each subsection of the convolutional layer's feature map. \n",
    "- Other types are *average pooling* and *sum pooling*\n",
    "- Pooling helps reduces the dimensions of the feature map produced by a convolutional layer \n",
    "\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td>            \n",
    "            <img src=\"images/max-pooling-downsampling.png\">\n",
    "        </td>\n",
    "        <td>\n",
    "            <img src=\"images/pooling-demos.gif\">\n",
    "            <p style=\"text-align: left;\">\n",
    "                Using $2\\times 2$ filters with a stride of $2$\n",
    "            </p>\n",
    "        </td>\n",
    "    <tr>\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fully Connected Layer:\n",
    "Why have a fully connected layer instead of directly skipping to the output layer? &mdash; The output of the convolutional layers represent high-level features in the data. Connecting this to fully connected layers prior to the output layer allows the network to learn non-linear combination of features\n",
    "\n",
    "To 'connect' the output of the pooling layer as input to the fully connected layers, you just have to *flatten* or reshape the feature map into a straight vector.\n",
    "\n",
    "<img src=\"images/pooling-to-fully-connected-flattening.png\" width=\"50%\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Softmax in the Output Layer:\n",
    "\n",
    "The $\\texttt{softmax}$ activation function takes in a vector of $N$ real numbers, applies $\\texttt{exp}$ to each element, then divides each element by the sum of the vector to return a vector of $N$ numbers between 0 and 1 which sum to 1 in total. The input numbers can be anywhere from $-\\infty$ to $\\infty$.\n",
    "\n",
    "Suppose there are $N$ classes and $z_j$ is the network's predicted probability for class $j$, where $1 \\leq j \\leq N$,\n",
    "\n",
    "$$\\texttt{Prob} (i) = \\frac{\\texttt{exp}(z_i)}{\\sum_{j=1}^{N} \\texttt{exp}(z_j)},$$\n",
    "$$\\texttt{logProb} (i) = z_i - \\log \\sum_{j=1}^{N} \\text{exp}(z_j).$$\n",
    "\n",
    "If the correct class is $i$, we can use $-\\texttt{logProb(i)}$ as the loss/cost function. The first term $z_i$ pushes up the correct class $i$ while the second term pushes down all the incorrect class, but preferentially pushes down the class $j$ that had the highest activation. The idea is that every incorrect class is pushed down in proportion to the network's predicted probability for it.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example: LeNet (1998)\n",
    "A convolutional network structure (called LeNet architecture) first introduced by Yann LeCun in 1998:\n",
    "\n",
    "<img src=\"images/LeNet.png\" width=\"100%\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analysing the structure:\n",
    "\n",
    "Suppose the input is $32 \\times 32$ and we use 6 convolutional filters of size $5 \\times 5$. \n",
    "\n",
    "- For each of the 6 convolutional filters, there exists $25$ weights for each colour channel, plus 1 bias, giving $76$ tunable parameters\n",
    "- The convolution layer output will have dimensions $28 \\times 28$. With 6 individual convolutional filters, we generate a 6 feature maps, giving an output of dimension $28 \\times 28 \\times 6 = 4056\n",
    "$\n",
    "- Each convolutional filter takes their 76 weights (including 1 bias) and operates on $28 \\times 28$ subsections of the input image. Repeated 6 times for each filter, this gives a total of $76 \\times 28 \\times 28 \\times 6 = 357504$ different connections \n",
    "- There are only $6 \\times 76 = 456$ individual parameters to tune within the convolution layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: AlexNet (2012)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A state-of-the-art convolutional network that maps images to 1000 different classes with an error rate of $\\approx 15\\%$.\n",
    "<img src=\"images/AlexNet.png\" width=\"100%\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Interesting notes:\n",
    "\n",
    "- Contains 62.3 million parameters to tune\n",
    "- Trains with 90 epochs over five or six days on two GTX 580 GPUs\n",
    "- Uses $\\texttt{ReLU}$ over $\\texttt{tanh}$ for non-linearity (increasing training speed by 6 times at the same accuracy)\n",
    "- Uses a dropout of $0.5$ to deal with overfitting\n",
    "- SGD with learning rate $\\eta = 0.01$, momentum 0.9 and weight decay 0.0005 is used.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resources:\n",
    "- <a href=\"https://towardsdatascience.com/intuitively-understanding-convolutions-for-deep-learning-1f6f42faee1\">Convolutional neural networks from first principles</a>\n",
    "- <a href=\"https://www.freecodecamp.org/news/an-intuitive-guide-to-convolutional-neural-networks-260c2de0a050/#:~:text=The%20main%20special%20technique%20in,describe%20an%20image%20with%20text.\">Intuitive guide to convolutional neural nets</a>\n",
    "- <a href=\"https://machinelearningmastery.com/convolutional-layers-for-deep-learning-neural-networks/\">Convolutional layers for deep learning neural networks</a>\n",
    "- <a href=\"https://medium.com/@smallfishbigsea/a-walk-through-of-alexnet-6cbd137a5637\">AlexNet architecture</a>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
