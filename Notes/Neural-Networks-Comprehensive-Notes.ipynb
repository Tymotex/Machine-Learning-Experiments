{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "Deep learning is a subset of machine learning, which is a subset of artificial intelligence.\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <th style=\"text-align: center;\">AI subfields</th>\n",
    "        <th style=\"text-align: center;\">A neural network</th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>            \n",
    "            <img src=\"images/ai-subsets.png\">\n",
    "        </td>\n",
    "        <td>\n",
    "            <img src=\"images/neural-net.png\">\n",
    "            <p style=\"text-align: left;\">\n",
    "                As a biological brain analogue, each node represents a neuron and each edge represents a synaptic connection\n",
    "            </p>\n",
    "        </td>\n",
    "    <tr>\n",
    "</table>\n",
    "\n",
    "Deep learning focuses on a particular class of machine learning algorithms called neural networks &mdash; deep neural networks in particular."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activation Functions (Nonlinearities):\n",
    "An activation function is a function associated with a given node which takes in the weighted sum (plus bias) and maps it to another number. Activation functions mimic the firing of neurons in biological neural networks. \n",
    "\n",
    "Activation functions should have the properties:\n",
    "- Continuous and differentiable at every $x$ in the real numbers\n",
    "- *Injective* &mdash; one unique output for each unique input. Simple tests: check the derivative is monotonically increasing or use the horizontal line test\n",
    "- *Non-linear* &mdash; not just a straight line. The relu function is a piecewise function so it's not linear in that way. Having a non-linear function is necessary for <em>conditional correlation</em>\n",
    "- Efficient to compute &mdash; because the activation function could be called a massive number of times\n",
    "\n",
    "The purpose of activation functions is to introduce non-linearity to the output of a neuron.\n",
    "\n",
    "- Non-linearity can be thought of as “the outcome does not change in proportion to a change in any of the inputs”\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Activation Functions for the Hidden Layer:\n",
    "- $\\texttt{logistic sigmoid}$: $\\frac{1}{1+e^{-x}}$ &mdash; maps weighted sums to a value in the interval $(0, 1)$\n",
    "    - __Derivative:__ suppose $z=\\frac{1}{1+e^{-x}}$, then $\\frac{dz}{dx}=z(1-z)$\n",
    "    - This lets you interpret the output of a neuron as a probability measure\n",
    "    \n",
    "<img src=\"images/sigmoid.png\" style=\"width: 35%\">\n",
    "\n",
    "- $\\texttt{tanh(x)}=\\frac{e^{x}-e^{-x}}{e^{x}+e^{-x}}=\\frac{2}{1+e^{-2x}} - 1=2 \\cdot S(2x) - 1$ &mdash; basically a scaled and offsetted version of logistic sigmoid.maps weighted sums to a value in the interval $(-1, 1)$. \n",
    "    - __Derivative:__ suppose $z=\\tanh(x)$, then $\\frac{dz}{dx}=1-z^2$ \n",
    "    - $\\texttt{tanh}$ can give a measure of negative correlation, rather than *just* positive correlation in the case of logistic sigmoid. It generally outperforms sigmoid for hidden layers because of its ability to measure negative correlation\n",
    "    - $\\texttt{tanh}$ has a steeper gradient around the neighbourhood of $x=0$ \n",
    "\n",
    "<img src=\"images/tanh.png\" style=\"width: 35%\">\n",
    "\n",
    "- $\\texttt{ReLU}=\\texttt{max(0, x)}$ &mdash; suppresses firing below 0, otherwise echoes the same input to the next layer.\n",
    "    - Computationally cheaper than the sigmoid functions.\n",
    "    - Unbounded y-values in the positive direction means the activation can 'blow-up'\n",
    "    - 'Dying ReLU problem' &mdash; for nodes that output 0, their weight cannot be adjusted during gradient descent since the gradient is 0. A substantial number of nodes in the network can become 'passive' because of that\n",
    "        - Leaky ReLU aims to mitigate this problem by ensuring nodes never have a non-zero gradient\n",
    "        \n",
    "<table>\n",
    "    <tr>\n",
    "        <th style=\"text-align: center;\">ReLU</th>\n",
    "        <th style=\"text-align: center;\">Leaky ReLU</th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>            \n",
    "            <img src=\"images/relu-graph.png\">\n",
    "        </td>\n",
    "        <td>\n",
    "            <img src=\"images/leaky-relu-graph.png\">\n",
    "        </td>\n",
    "    <tr>\n",
    "</table>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Activation Functions for the Output Layer:\n",
    "The choice of activation function in the <em>output layer</em> depends on what prediction is being made.\n",
    "- $\\texttt{sigmoid}$ &mdash; for yes/no probability predictions. \n",
    "    - Eg. is this a dog?\n",
    "- $\\texttt{softmax}$ &mdash; for classifications, based on highest probabilities (selecting a single label out of many possible labels). \n",
    "    - Eg. does this number look like a 1, a 3 or a 7? ]\n",
    "    - $\\texttt{softmax}$ serves as a normalising function for when the network needs to classify an input in two or more classes\n",
    "- No activation function for the output layer &mdash; for non-probability predictions. \n",
    "    - Eg. what will the temperature be tomorrow?\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss Functions:\n",
    "A loss function measures how closely the prediction matches the true label.\n",
    "\n",
    "-  Regression Loss Functions:\n",
    "    - __*Mean squared error*__: $E(t, z) = \\frac{1}{2}\\sum_{i=1}^{m} (t-z)^2$ &mdash; the sum of the squared difference between expected value $t$ and the forward-propagation's predicted value $z$\n",
    "\n",
    "- Binary Classification Loss Functions:\n",
    "    - __*Cross-entropy*__: $E(t, z) = -(t\\log z + (1-t)\\log (1-z))$ &mdash; where $t$ is the expected value and $z$ is the forward-propagation's prediction\n",
    "    - When $t=1$, the second term disappears, leaving $E(t, z) = -t\\log z$\n",
    "    - When $t=0$, the first term disappears, leaving $E(t, z) = -(1-t)\\log (1-z)$\n",
    "\n",
    "- Multi-Class Classification Loss Functions:\n",
    "    - __*KL-Divergence Loss*__ &mdash; TODO\n",
    "\n",
    "#### Cost Function\n",
    "Cost function: $J(w, b) = \\frac{1}{m}\\sum_{i=1}^m E(t^{(i)}, z^{(i)})$ &mdash; the average of the sum of loss values for all training samples $1 \\leq i \\leq m$, where $w$ and $b$ are the weight and bias.\n",
    "- The loss function measures how well the network performed on a single training example\n",
    "- The cost function measures how well the network's parameters $w$ and $b$ performed on the entire training set\n",
    "- Eg. if our loss function was cross-entropy, then the cost function would be: $J(w, b) = -\\frac{1}{m}\\sum_{i=1}^m \\big( t^{(i)}\\log y^{(i)} + (1-t^{(i)}) \\log (1-z^{(i)}) \\big)$.\n",
    "\n",
    "\n",
    "The 'learning' of a neural network is the process of finding $w$ and $b$ so as to minimise $J$. This is done through an optimisation algorithm such as __*gradient descent*__.\n",
    "\n",
    "\n",
    "#### Error/Cost Landscape:\n",
    "If we think of $E$ has height, then each the loss function defines an 'error landscape' on the weight space. The aim of neural network training then is just to find a configuration of weights where $E$ takes the global minimum.\n",
    "\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <th style=\"text-align: center;\">Error landscape</th>\n",
    "        <th style=\"text-align: center;\">Cost landscape</th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>            \n",
    "            <img src=\"images/error-landscape.png\">\n",
    "        </td>\n",
    "        <td>\n",
    "            <img src=\"images/cost-landscape.png\">\n",
    "            <div style=\"text-align: left;\">\n",
    "                Where $w$ and $b$ are real numbers just to make this possible to visualise. Of course, $w$ would be higher dimensional. \n",
    "            </div>\n",
    "        </td>\n",
    "    <tr>\n",
    "</table>\n",
    "\n",
    "The partial derivative $\\frac{\\partial J(w, b)}{\\partial w}$ gives the slope along the $w$ axis, while $\\frac{\\partial J(w, b)}{\\partial b}$ gives the slope along the $b$ axis. When you 'nudge' $w$ a little bit, the derivative $\\frac{\\partial J(w, b)}{\\partial w}$ tells you how much $J(w, b)$ changes.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Descent:\n",
    "\n",
    "Gradient descent is an optimisation algorithm for finding the local minimum of a differentiable function. \n",
    "\n",
    "It works by repeatedly taking steps proportional to the negative of the gradient, until the weight converges on a global minimum:\n",
    "\n",
    "$$w_{new} = w_{old} - \\underbrace{\\eta \\frac{\\partial E}{\\partial w}}_\\text{step}$$\n",
    "\n",
    "Where $\\eta$ is the learning rate &mdash; how big of step the weight update should take, or how fast the gradient descends towards an optimal weight.\n",
    "- The subtraction of the derivative term or slope value, $\\frac{\\partial E}{\\partial w}$, will always be push the value in the 'downhill' direction\n",
    "\n",
    "- Higher learning rates can cause gradient descent to overshoot and 'bounce' up the convex error landscape. Slower learning rates cause slower training time and may cause the network to get stuck \n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <th style=\"text-align: center;\">Gradient Descent</th>\n",
    "        <th style=\"text-align: center;\">Fast vs. slow learning rate</th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>            \n",
    "            <img src=\"images/gradient-descent-demo.png\">\n",
    "        </td>\n",
    "        <td>\n",
    "            <img src=\"images/gradient-descent-fast-vs-slow.png\">\n",
    "        </td>\n",
    "    <tr>\n",
    "</table>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimisers:\n",
    "\n",
    "Given an algorithm f(x), an optimization algorithm help in either minimizing or maximizing the value of f(x). In deep learning, we use optimisers to train the neural network by minimising the error/cost function.\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td width=\"50%\">   \n",
    "            <p style=\"text-align: center;\">\n",
    "                <strong>A few standard optimisers</strong>\n",
    "            </p>\n",
    "            <img src=\"images/optimisers.png\">\n",
    "        </td>\n",
    "        <td>\n",
    "            <p style=\"text-align: center;\">\n",
    "                <strong>Different optimisers traversing the error landscape</strong>\n",
    "            </p>\n",
    "            <img src=\"images/optimisers-visualised.gif\">\n",
    "        </td>\n",
    "    <tr>\n",
    "</table>\n",
    "\n",
    "The best optimiser is the one that traverse the error landscape for the specific problem the best. The choice of optimiser is made empirically rather than mathemtically, mostly. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stochastic Gradient Descent:\n",
    "\n",
    "Stochastic gradient descent is when we update the weights after each training example rather than after a whole epoch (vanilla gradient descent).\n",
    "- The problem with this is that a noisy training sample can steer the jump away from the optimum.\n",
    "\n",
    "\n",
    "\n",
    "#### Stochastic Gradient Descent + Momentum:\n",
    "One way to decrease the noise associated with stochastic gradient descent is to add momentum. With this, it can pay less attention to the occasional noisy samples that throw it off.\n",
    "\n",
    "\n",
    "*coefficient of momentum* &mdash; the percentage of gradient from previous iterations that is retained. The gradient changes of the more recent steps have a greater weighting.\n",
    "    - Usually initialised as $\\eta = 0.5$ and may be changed over later epochs\n",
    "\n",
    "<img src=\"images/sgd-momentum.png\" width=\"70%\">\n",
    "\n",
    "Since the steps taken can get larger and larger, it may be easy to overshoot the minima.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Momentum takes into account the gradient of previous steps.\n",
    "\n",
    "Momentum helps gradient descent converge quicker towards one direction and dampens oscillations.\n",
    "\n",
    "\n",
    "#### Stochastic Gradient Descent + Momentum + Acceleration:\n",
    "One way to decrease the noise associated with stochastic gradient descent is to add momentum. With this, it can pay less attention to the occasional noisy samples that throw it off.\n",
    "\n",
    "\n",
    "\n",
    "#### Mini-Batch Gradient Descent:\n",
    "\n",
    "Mini-batch gradient descent &mdash; only updating after $m$ number of training examples are done, rather than after a whole epoch or after 1 training sample.\n",
    "\n",
    "\n",
    "#### NAG &mdash; Nesterov Accelerated Gradient:\n",
    "\n",
    "\n",
    "#### Adagrad &mdash; Adaptive Gradient:\n",
    "\n",
    "\n",
    "#### Adadelta:\n",
    "\n",
    "\n",
    "#### RMSProp:\n",
    "\n",
    "\n",
    "#### Adam &mdash; Adaptive Moment Optimisation:\n",
    "Combines momentum and RMSProp?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computational Graph\n",
    "\n",
    "Fundamentally, all neural networks are just a single big mathematical function.\n",
    "\n",
    "When trying to find a neural network that works for a particular application, you're implicitly saying 'there exists some mathematical function that will reasonably approximate the observed behaviour'. The training of neural networks is to find this approximating function.\n",
    "\n",
    "A computational graph is a way of representing math functions in graph theory.\n",
    "\n",
    "#### Representing Functions:\n",
    "\n",
    "Each node is either an input node, or a function node. Function nodes take in input and produce an output.\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <th style=\"text-align: center;\">Representing $f(x, y, z)=(x+y) \\cdot z$</th>\n",
    "        <th style=\"text-align: center;\">Representing $f(x, y)=ax^2+bxy+cy^2$</th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>            \n",
    "            <img src=\"images/simple-computational-graph.png\">\n",
    "        </td>\n",
    "        <td>\n",
    "            <img src=\"images/another-computational-graph.png\">\n",
    "            <p style=\"text-align: left;\">\n",
    "                This could technically be considered a neural network. It's possible to train it with gradient descent and backprop and tune $a, b$ and $c$ if we had a training dataset\n",
    "            </p>\n",
    "        </td>\n",
    "    <tr>\n",
    "</table>\n",
    "\n",
    "#### Representing Neural Networks:\n",
    "Even simple neural networks may have hundreds of thousands of nodes and edges in their computational graph, which would be impossible to represent in standard function notation.\n",
    "\n",
    "Each node in a neural network encapsulates smaller function nodes for: performing a weighted sum (plus bias), then computing a non-linear activation function.\n",
    "\n",
    "<img src=\"images/neural-node-computational-graph.png\" width=\"50%\" />\n",
    "\n",
    "With deep neural nets, we could have millions of individual weights, plus thousands of biases to individually tune. This is why a massive dataset and a massive amount of computing power is required.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Back-Propagation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The aim of back-propagation + gradient descent is to update the weights based on the error function value after forward-propagation. The aim is to attribute the *cause of the error*, ie. to assign a proportionate magnitude of 'blame' or 'praise', to each node to penalise/boost their output weight accordingly.\n",
    "\n",
    "Gradient descent requires the concrete values of $\\frac{\\partial E}{\\partial w_{ij}}$ &mdash; the amount $E$ changes when you nudge $w_{ij}$ &mdash; to be known for each weight in the network. Backpropagation is the algorithm used to calculate these gradients, it does not do anything more than that.\n",
    "    \n",
    "\n",
    "Gradients are calculated from the last layer to the first layer. Partial computation of the gradient from one layer is reused in the computation of the gradients in the previous layer.\n",
    "\n",
    "- The reuse of calculated gradients from each layer is what makes backpropagation more efficient than the naive approach of individually calculating the gradients $\\frac{\\partial E}{\\partial w_{ij}}$ for all $i, j$.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### Visualised\n",
    " \n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/backprop-simple.png\" width=\"100%\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\frac{\\partial C}{\\partial w^{(3)}}\n",
    "    =\n",
    "    \\frac{\\partial C}{\\partial a^{(3)}}\n",
    "    \\frac{\\partial a^{(3)}}{\\partial z^{(3)}}\n",
    "    \\frac{\\partial z^{(3)}}{\\partial w^{(3)}}\n",
    "\\tag{Weights from layer 2 to 3}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\frac{\\partial C}{\\partial w^{(2)}}\n",
    "    =\n",
    "    \\underbrace{\n",
    "    \\frac{\\partial C}{\\partial a^{(3)}}\n",
    "    \\frac{\\partial a^{(3)}}{\\partial z^{(3)}}\n",
    "    }_\\text{From $w^{(3)}$}\n",
    "    \\,\n",
    "    \\frac{\\partial z^{(3)}}{\\partial a^{(2)}}\n",
    "    \\frac{\\partial a^{(2)}}{\\partial z^{(2)}}\n",
    "    \\frac{\\partial z^{(2)}}{\\partial w^{(2)}}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\frac{\\partial C}{\\partial w^{(1)}}\n",
    "    =\n",
    "    \\underbrace{\n",
    "    \\frac{\\partial C}{\\partial a^{(3)}}\n",
    "    \\frac{\\partial a^{(3)}}{\\partial z^{(3)}}\n",
    "    }_\\text{From $w^{(3)}$}\n",
    "    \\,\n",
    "    \\underbrace{\n",
    "    \\frac{\\partial z^{(3)}}{\\partial a^{(2)}}\n",
    "    \\frac{\\partial a^{(2)}}{\\partial z^{(2)}}\n",
    "    }_\\text{From $w^{(2)}$}\n",
    "    \\,\n",
    "    \\frac{\\partial z^{(2)}}{\\partial a^{(1)}}\n",
    "    \\frac{\\partial a^{(1)}}{\\partial z^{(1)}}\n",
    "    \\frac{\\partial z^{(1)}}{\\partial w^{(1)}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resources:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Introduction:\n",
    "    - <a href=\"https://medium.com/tebs-lab/introduction-to-deep-learning-a46e92cb0022\">Intro to deep learning</a>\n",
    "- <a href=\"https://medium.com/datadriveninvestor/overview-of-different-optimizers-for-neural-networks-e0ed119440c3\">Types of optimisers</a>\n",
    "- Computation graph: \n",
    "    - <a href=\"https://medium.com/tebs-lab/deep-neural-networks-as-computational-graphs-867fcaa56c9#:~:text=A%20computational%20graph%20is%20a,or%20functions%20for%20combining%20values.\">Basics of computational graphs</a>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
