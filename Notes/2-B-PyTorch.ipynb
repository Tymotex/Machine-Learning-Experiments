{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Snippets of neural network definitions and other essential building blocks in PyTorch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boilerplate Structure of a PyTorch Program (Supervised Learning):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyTorch models can be deployed on a CPU or GPU\n",
    "net = MyModel().to(device)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(...)\n",
    "test_loader = torch.utils.data.DataLoader(...)\n",
    "\n",
    "# Choosing an optimiser, eg. stochastic gradient descent, Adam, etc.\n",
    "optimizer = torch.optim.SGD(net.parameters,...)\n",
    "\n",
    "# Training is done in epochs\n",
    "for epoch in range(1, epochs):\n",
    "    train(params, net, device, train_loader, optimizer)\n",
    "    if epoch % 10 == 0:\n",
    "        test(params, net, device, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining a Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inherits from the torch.nn.Module class \n",
    "class MyModel(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyModel, self).__init__()\n",
    "        # The structure of the network is defined here\n",
    "    \n",
    "    def forward(self, input):\n",
    "        # Run the input through the network and return the prediction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining a Custom Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the function $(x,y) \\mapsto Ax\\log (y) + By^2$,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyModel, self).__init__()\n",
    "        # The Parameter constructor needs to be given a torch tensor. \n",
    "        # Here we're creating a tensor of size 1 and initialise it with a random Gaussian value\n",
    "        # Since the aim is to tune this parameter, we set requires_grad=True \n",
    "        self.A = nn.Parameter(torch.randn((1), requires_grad=True))\n",
    "        self.B = nn.Parameter(torch.randn((1), requires_grad=True))\n",
    "    def forward(self, input):\n",
    "        output = self.A * input[:,0] * torch.log(input[:,1]) + self.B * input[:,1] * input[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building a Neural Net from Individual Components:\n",
    "The following network would be suitable model for the XOR multi-layer perceptron."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyModel, self).__init__()\n",
    "        # From an input layer with 2 nodes to a hidden layer with 2 nodes\n",
    "        self.in_to_hid  = torch.nn.Linear(2, 2)\n",
    "        # From a hidden layer with 2 nodes to an output layer with 1 node\n",
    "        self.hid_to_out = torch.nn.Linear(2, 1)\n",
    "    \n",
    "    def forward(self, input):\n",
    "        # Takes the input vector and multiplies it with the weight matrix from input layer -> hidden layer\n",
    "        hid_sum = self.in_to_hid(input)\n",
    "        \n",
    "        # Apply tanh on each component of the hidden layer's output\n",
    "        hidden  = torch.tanh(hid_sum)\n",
    "        \n",
    "        # Matrix multiplication of hidden layer output with the weights going into the output layer\n",
    "        out_sum = self.hid_to_out(hidden)\n",
    "        \n",
    "        # Applying the sigmoid function on the final output\n",
    "        output  = torch.sigmoid(out_sum)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image.png](images/xor-network.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining a Sequential Network:\n",
    "Modules are added in the order that they are passed into the $\\texttt{Sequential}$ constructor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(torch.nn.Module):\n",
    "    def __init__(self, num_input, num_hidden, num_out):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            nn.Linear(num_input, num_hidden),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(num_hidden, num_out),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    def forward(self, input):\n",
    "        output = self.main(input)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sequential Components:\n",
    "- Neural network layers:\n",
    "    - $\\texttt{nn.Linear()}$   — for linear layers\n",
    "    - $\\texttt{nn.Conv2d()}$   — for 2D convolutional layers\n",
    "   \n",
    "- Intermediate operators — these are applied *prior* to the activation function\n",
    "    - $\\texttt{nn.Dropout()}$\n",
    "    - $\\texttt{nn.BatchNorm()}$\n",
    "\n",
    "- Activation functions:\n",
    "    - $\\texttt{nn.Tanh()}$\n",
    "    - $\\texttt{nn.Sigmoid()}$\n",
    "    - $\\texttt{nn.ReLU()}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Working With Data:\n",
    "The following snippet declares the input dataset for the XOR network and the expected output predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils.data\n",
    "\n",
    "input    = torch.Tensor([0, 0],\n",
    "                        [0, 1],\n",
    "                        [1, 0],\n",
    "                        [1, 1])\n",
    "expected = torch.Tensor([0],\n",
    "                        [1],\n",
    "                        [1],\n",
    "                        [0])\n",
    "\n",
    "# TensorDataset forms the training dataset from the input samples and corresponding target outputs\n",
    "xdata        = torch.utils.data.TensorDataset(input, expected)\n",
    "train_loader = torch.utils.data.DataLoader(xdata, batch_size=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Batch size: \n",
    "*Batch size* is a hyperparameter of gradient descent. The $\\texttt{batch_size}$ defines the number of input datapoints to be propagated through the network, after which, the network's weights are updated. \n",
    "\n",
    "Eg. specifying a batch size of 100 will use the first 100 datapoints from the input dataset to train the network for the first training iteration. For the next iteration, it takes the next 100 datapoints from the input dataset to train the network, and so on.\n",
    "\n",
    "Training in mini-batches:\n",
    "- Requires less memory. You can't fit a massive dataset in memory all at once\n",
    "- Weights are learned more quickly since we are making updates after each batch is completed, as opposed to making 1 single update after the entire input dataset has been propagated through\n",
    "- Becomes less accurate the smaller the batch\n",
    "\n",
    "#### Epoch and Iterations:\n",
    "An *epoch* is one complete iteration through the *entire* dataset, forward and backward through the network.\n",
    "\n",
    "An *iteration* is the number of batches in 1 epoch.\n",
    "\n",
    "Since gradient descent is an iterative process, making further epochs will converge the weights closer to 0% error. Only running one epoch usually leads to underfitting. Running too many epochs will usually lead to overfitting. The number of epochs depends on the diversity of the training dataset's samples.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classic Datasets\n",
    "\n",
    "For some widely used datasets, we have special methods just for fetching them online and then loading for training. See a list of classic datasets provided by pytorch <a href=\"https://pytorch.org/docs/stable/torchvision/datasets.html\">here</a>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.datasets as dsets\n",
    "\n",
    "mnist    = dsets.MNIST(...)       # Handwritten digits dataset\n",
    "cifarset = dsets.CIFAR10(...)     # Animal and vehicle images dataset\n",
    "celebset = dsets.CelebA(...)      # Celebrity pictures dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choosing an Optimiser: \n",
    "\n",
    "Constructing optimiser object in PyTorch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = MyModel.to(device)\n",
    "...\n",
    "\n",
    "# Stochastic gradient descent\n",
    "optimiser = torch.optim.SGD(\n",
    "    net.parameters(), \n",
    "    lr=0.01, \n",
    "    momentum=0.9, \n",
    "    weight_decay=0.0001\n",
    ") \n",
    "\n",
    "# Adaptive moment estimation\n",
    "optimiser = torch.optim.Adam(\n",
    "    net.parameters(), \n",
    "    eps=0.000001, \n",
    "    lr=0.01, \n",
    "    betas=(0.5, 0.999), \n",
    "    weight_decay=0.0001\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the Network:\n",
    "A high-level structure for neural network training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(args, net, device, train_loader, optimiser):\n",
    "    for batch_index, (data, target) in enumerate(train_loader):\n",
    "        optimiser.zero_grad()   # Zero the gradients\n",
    "        output = net(data)      # Get prediction\n",
    "        loss = ...              # Compute loss function\n",
    "        loss.backward()         # Update gradients (backpropagate)\n",
    "        optimiser.step()        # Update the weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss Functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "loss = torch.sum((output - expected) ** 2)       # Mean squared error\n",
    "\n",
    "# Predefined loss functions\n",
    "loss = F.nll_loss(output, expected)              # Negative log likelihood\n",
    "loss = F.binary_cross_entropy(output, expected)  # Cross entropy (for a 2-class classification)\n",
    "loss = F.softmax(output, dim=1)                  # Softmax\n",
    "loss = F.log_softmax(output, dim=1)              # Log softmax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(args, model, device, test_loader):\n",
    "    # Suppress the update of gradients since we're meant\n",
    "    # to leave the network unchanged in testing\n",
    "    with torch.no_grad():\n",
    "        # Toggles batch norm and dropout since these are for training purposes\n",
    "        net.eval()\n",
    "        \n",
    "        test_loss = 0\n",
    "        for data, target in test_loader:\n",
    "            output = model(data)\n",
    "            test_loss += ...\n",
    "        print(test_loss)\n",
    "        \n",
    "        # Toggle batch norm and dropout after the testing is done\n",
    "        net.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computational Graph:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Controlling the Computational Graph:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    If we need to block gradients from being backpropagated through\n",
    "    a certain variable, A, we can exclude it from the computational\n",
    "    graph with the detach method:\n",
    "\"\"\"\n",
    "A.detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    loss.backward() discards the computational graph after computing\n",
    "    the gradients. To keep the computational graph, set retain_graph=True\n",
    "\"\"\"\n",
    "loss.backward(retain_graph=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height: 3px\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensors Theory:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensor — a rank-$n$ tensor in $m$-dimensions is a mathematical object with $n$ indices and $m^n$ *components* and obeys certain transformation rules.\n",
    "\n",
    "- \"Tensor\" comes \"to stretch\" in Latin.\n",
    "- A vector *is a* tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Continuum Mechanics:\n",
    "In *continuum mechanics*, *stress* is a physical quantity that expresses the internal forces that neighbouring particles of a continuous material exert on each other.\n",
    "\n",
    "Consider a cube in 3D space. It can be 'stretched' in 3 separate dimensions and 'sheared' in 6 directions:\n",
    "\n",
    "<table style=\"width: 75%\">\n",
    "    <tr>\n",
    "        <td>\n",
    "            <img src='images/shear-cube.png'>\n",
    "        </td>\n",
    "        <td>\n",
    "            <img src='images/stress-tensor-cube.png'>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>\n",
    "\n",
    "\n",
    "These 9 different stresses that can be applied to the cube are organised into a *stress tensor* like this: \n",
    "$\n",
    "    \\begin{pmatrix}\n",
    "    \\sigma_{11} & \\sigma_{12} & \\sigma_{13} \\\\\n",
    "    \\sigma_{21} & \\sigma_{22} & \\sigma_{23} \\\\\n",
    "    \\sigma_{31} & \\sigma_{32} & \\sigma_{33} \\\\\n",
    "    \\end{pmatrix}\n",
    "$.\n",
    "Each row and column correspond to a physical dimension (x, y and z).\n",
    "\n",
    "<strong>*Rank*</strong> can be thought of as the amount of information you need to find a specific *component*. Formally, rank is the number of *basis vectors* required to fully specify a *component* of the tensor.\n",
    "\n",
    "For example, since we can identify any $\\sigma_{ij}$ by specifying the row and the column, we say that this tensor is rank-$2$ and $3$-dimension. Note that the number of components is given by $dim^{rank}=3^2=9$.\n",
    "\n",
    "<img src=\"images/different-rank-tensors.png\" width=\"50%\">\n",
    "\n",
    "In general, we just use index notation instead of matrix notation to specify tensors, since matrix notation breaks beyond rank-$2$.\n",
    "\n",
    "Note that a rank-$2$ tensor is not the same as a matrix. Fundamentally, a matrix is just a data structure for numbers. A tensor, on the other hand, is a data structure that *obeys certain transformation rules*.\n",
    "\n",
    "Tensors have a deeper physical significance. \n",
    "\n",
    "#### Transformation Rules:\n",
    "- A tensor is *invariant* under a change in the coordinate system. During a change to the coordinate system, the components change according to a special set of equations, but the vector itself has not been affected. Eg. think of a displacement vector between two objects in 3D space — its components will certainly change if the coordinate system is rotated, displaced, etc., but the actual displacement vector itself preserves its physical meaning.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch Cookbook:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dependencies:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensors:\n",
    "\n",
    "Tensors are multi-dimensional arrays with support for `autograd` operations like `backward()`. Tensors in PyTorch are similar to tensors in NumPy, except that they can be used on a GPU. \n",
    "\n",
    "### Creating Tensors:\n",
    "\n",
    "- $\\texttt{torch.rand(shape)}$ &mdash; returns a tensor with random values drawn from a uniform distribution on interval $[0, 1)$\n",
    "- $\\texttt{torch.zeros(shape)}$ &mdash; returns a tensor where all components are initialised with zeroes\n",
    "- $\\texttt{torch.tensor(data)}$ &mdash; creates a tensor from the supplied data list/array \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensor Properties:\n",
    "\n",
    "Tensors have the following methods:\n",
    "- $\\texttt{size()}$ &mdash; returns a tuple-like object containing the tensor's shape\n",
    "- $\\texttt{transpose(dim0, dim1)}$ &mdash; returns a transposed tensor\n",
    "    - Eg. `x.transpose(0, 1)` transposes a 2D tensor\n",
    "- $\\texttt{reshape(shape)}$ &mdash; returns a reshaped tensor, containing the same data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Original tensor =====\n",
      "tensor([[0.3419, 0.6078, 0.1113],\n",
      "        [0.8531, 0.7973, 0.0528]])\n",
      "Size: torch.Size([2, 3])\n",
      "===== Transpose =====\n",
      "tensor([[0.3419, 0.8531],\n",
      "        [0.6078, 0.7973],\n",
      "        [0.1113, 0.0528]])\n",
      "===== Reshape ====\n",
      "tensor([[0.3419, 0.8531, 0.6078, 0.7973, 0.1113, 0.0528]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand((2, 3))\n",
    "print(\"===== Original tensor =====\")\n",
    "print(x)\n",
    "print(\"Size: {}\".format(x.size()))\n",
    "\n",
    "x = x.transpose(0, 1)\n",
    "print(\"===== Transpose =====\")\n",
    "print(x)\n",
    "\n",
    "print(\"===== Reshape ====\")\n",
    "x = x.reshape((1, 6))\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensor operations:\n",
    "\n",
    "The elementwise math operators `+`, `-`, `*`, `/` can be used on any two size-compatible tensors.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x = tensor([1., 2., 3.])\n",
      "y = tensor([4., 5., 6.])\n",
      "===== Operations =====\n",
      "x + y = tensor([5., 7., 9.])\n",
      "x - y = tensor([-3., -3., -3.])\n",
      "x * y = tensor([ 4., 10., 18.])\n",
      "x / y = tensor([0.2500, 0.4000, 0.5000])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([1.0, 2.0, 3.0])\n",
    "y = torch.tensor([4.0, 5.0, 6.0])\n",
    "print(\"x = {}\".format(x))\n",
    "print(\"y = {}\".format(y))\n",
    "\n",
    "print(\"===== Operations =====\")\n",
    "print(\"x + y = {}\".format(x + y))\n",
    "print(\"x - y = {}\".format(x - y))\n",
    "print(\"x * y = {}\".format(x * y))\n",
    "print(\"x / y = {}\".format(x / y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Converting between torch tensor and numpy array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== torch.Tensor to numpy.ndarray =====\n",
      "Torch tensor: tensor([1, 2, 3])\n",
      "Numpy array:  [1 2 3]\n",
      "===== numpy.ndarray to torch.Tensor =====\n",
      "Numpy array:  [1 2 3]\n",
      "Torch tensor: tensor([1, 2, 3])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "print(\"===== torch.Tensor to numpy.ndarray =====\")\n",
    "x = torch.tensor([1, 2, 3])\n",
    "print(\"Torch tensor: {}\".format(x))\n",
    "x = x.numpy()\n",
    "print(\"Numpy array:  {}\".format(x))\n",
    "\n",
    "print(\"===== numpy.ndarray to torch.Tensor =====\")\n",
    "x = np.array([1, 2, 3])\n",
    "print(\"Numpy array:  {}\".format(x))\n",
    "x = torch.from_numpy(x)\n",
    "print(\"Torch tensor: {}\".format(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CUDA Tensors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.3606, 2.1739, 3.9428]], device='cuda:0')\n",
      "tensor([[1.3606, 2.1739, 3.9428]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# The following this cell is only run if CUDA is available\n",
    "# We will use `torch.device` objects to move tensors in and out of GPU\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")          # a CUDA device object\n",
    "    y = torch.rand((1, 3), device=device)  # directly create a tensor on GPU\n",
    "    x = x.to(device)                       # or just use strings ``.to(\"cuda\")``\n",
    "    z = x + y\n",
    "    print(z)\n",
    "    print(z.to(\"cpu\", torch.double))       # `.to` can also change dtype together!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autograd &mdash; Automatic Differentiation:\n",
    "\n",
    "The `autograd` package provides automatic differentiation for all operations on Tensors.\n",
    "\n",
    "- Enabling tracking:\n",
    "    - Setting `requires_grad=True` on a new tensor tracks all the computation done on it. Once the computations are done, you can call `.backward()` to have all the gradients computed automatically. \n",
    "- Disabling tracking:\n",
    "    - `.detach()` method prevents computation tracking\n",
    "    - Wrapping the code block in `with torch.no_grad()` blocks tracking for everything within the block. Useful for when we're testing the model rather than training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Computation tracking example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x = tensor([[1., 1.],\n",
      "        [1., 1.]], requires_grad=True)\n",
      "y = tensor([[3., 3.],\n",
      "        [3., 3.]], grad_fn=<AddBackward0>)\n",
      "y.grad_fn = <AddBackward0 object at 0x7f6744035dc0>\n",
      "z = tensor([[27., 27.],\n",
      "        [27., 27.]], grad_fn=<MulBackward0>)\n",
      "z.grad_fn = <MulBackward0 object at 0x7f6744035dc0>\n",
      "Theta of z = 27.0\n",
      "Theta.grad_fn = <MeanBackward0 object at 0x7f67c434fac0>\n",
      "dθ/dx = tensor([[4.5000, 4.5000],\n",
      "        [4.5000, 4.5000]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.ones(2, 2, requires_grad=True)\n",
    "print(\"x = {}\".format(x))\n",
    "\n",
    "y = x + 2\n",
    "print(\"y = {}\".format(y))\n",
    "print(\"y.grad_fn = {}\".format(y.grad_fn))   # y was created as a result of an operation on x, so it has a grad_fn\n",
    "\n",
    "z = y * y * 3\n",
    "print(\"z = {}\".format(z))\n",
    "print(\"z.grad_fn = {}\".format(z.grad_fn))\n",
    "\n",
    "theta = z.mean()\n",
    "print(\"Theta of z = {}\".format(theta))\n",
    "print(\"Theta.grad_fn = {}\".format(theta.grad_fn))\n",
    "\n",
    "# Doing backpropagation:  (note that calling backward() is only valid on a scalar)\n",
    "theta.backward()\n",
    "\n",
    "print(\"dθ/dx = {}\".format(x.grad))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{split}\n",
    "    \\frac{\\partial \\theta}{\\partial x} & = \\frac{\\partial \\theta}{\\partial z} \\cdot \\frac{\\partial z}{\\partial y} \\cdot \\frac{\\partial y}{\\partial x} \\\\\n",
    "    & = \n",
    "        \\begin{pmatrix}\n",
    "            \\frac{1}{4} & \\frac{1}{4}\\\\\n",
    "            \\frac{1}{4} & \\frac{1}{4}\n",
    "        \\end{pmatrix}\n",
    "     \\cdot 6\\big(\n",
    "        \\begin{pmatrix}\n",
    "            x_{11} & x_{12} \\\\\n",
    "            x_{21} & x_{22}\n",
    "        \\end{pmatrix}\n",
    "     +\n",
    "        \\begin{pmatrix}\n",
    "            2 & 2 \\\\\n",
    "            2 & 2\n",
    "        \\end{pmatrix}\n",
    "    \\big) \\cdot \n",
    "        \\begin{pmatrix}\n",
    "            1 & 1 \\\\\n",
    "            1 & 1\n",
    "        \\end{pmatrix}\n",
    "    \\\\\n",
    "    & = \n",
    "        \\begin{pmatrix}\n",
    "            \\frac{1}{4} & \\frac{1}{4}\\\\\n",
    "            \\frac{1}{4} & \\frac{1}{4}\n",
    "        \\end{pmatrix}\n",
    "    \\cdot 6\\big(\n",
    "        \\begin{pmatrix}\n",
    "            1 & 1 \\\\\n",
    "            1 & 1\n",
    "        \\end{pmatrix}\n",
    "    +\n",
    "        \\begin{pmatrix}\n",
    "            2 & 2 \\\\\n",
    "            2 & 2\n",
    "        \\end{pmatrix}\n",
    "    \\big) \\cdot \n",
    "        \\begin{pmatrix}\n",
    "            1 & 1 \\\\\n",
    "            1 & 1\n",
    "        \\end{pmatrix} \\\\\n",
    "    & = \n",
    "        \\begin{pmatrix}\n",
    "            4.5 & 4.5 \\\\\n",
    "            4.5 & 4.5 \n",
    "        \\end{pmatrix}\n",
    "\\end{split}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a href=\"https://pytorch.org/docs/stable/nn.html\">`Torch.nn`</a>\n",
    "\n",
    "`nn.Module` &mdash; base class for all neural network modules. Convenient for encapsulating parameters, keep track of state and has helpers for moving them to the GPU\n",
    "- `parameters()` &mdash; returns an iterator containing the network's parameters\n",
    "- `zero_grad()` &mdash; zeroes the gradient buffers of all parameters. It's necessary to zero the gradients prior to backpropagation because PyTorch accumulates gradients on subsequent backward passes by default\n",
    "\n",
    "\n",
    "#### Loss Functions:\n",
    "There are several different error functions available in the `nn` package. They all take in an $\\texttt{(prediction, target)}$ pair and give back a value that indicates the magnitude of prediction error\n",
    "- `MSELoss` &mdash; mean squared error\n",
    "- `CrossEntropyLoss` &mdash; cross entropy error\n",
    "\n",
    "### Optimisers (from `torch.optim`):\n",
    "- `SGD(net.parameters(), lr, momentum)`\n",
    "- `Adam([var, var2], lr)`\n",
    "\n",
    "#### Optimiser methods:\n",
    "- `zero_grad()`\n",
    "- `step()` &mdash; updates the network parameters. Called once the gradients have been computed by `backward()`\n",
    "\n",
    "\n",
    "### Building Blocks:\n",
    "\n",
    "- `Linear(in_size, out_size)` &mdash; applies linear transformation: $y=xA^T+b$\n",
    "- `Conv2d(in_channels, out_channels, kernel_size, stride, padding)` &mdash; a 2D convolutional layer\n",
    "- `MaxPool2d()`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height: 2px;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch Example Models: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handwritten Digits Classifier:\n",
    "\n",
    "Below is a network that classifies handwritten digits.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/pytorch-sample-network.png\" width=\"80%\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv2d(1, 6, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=576, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n",
      "Network parameters\n",
      "    torch.Size([6, 1, 3, 3])\n",
      "    torch.Size([6])\n",
      "    torch.Size([16, 6, 3, 3])\n",
      "    torch.Size([16])\n",
      "    torch.Size([120, 576])\n",
      "    torch.Size([120])\n",
      "    torch.Size([84, 120])\n",
      "    torch.Size([84])\n",
      "    torch.Size([10, 84])\n",
      "    torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        # Convolutional layers\n",
    "        self.conv1 = nn.Conv2d(1, 6, 3)  # 1 input image channel, 6 output channels, 3x3 convolution kernel\n",
    "        self.conv2 = nn.Conv2d(6, 16, 3) # 6 input channels, 16 output channels, 3x3 kernels\n",
    "        \n",
    "        # Fully connected layers\n",
    "        self.fc1 = nn.Linear(16 * 6 * 6, 120)  # 6*6 from image dimension\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    # Note: the backward() function is automatically defined by autograd\n",
    "    def forward(self, x):\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2)) # Max pooling over a (2, 2) window on conv1\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)      # Max pooling over a (2, 2) window on conv2\n",
    "        x = x.view(-1, self.num_flat_features(x))       # Flattening(?)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features\n",
    "\n",
    "\n",
    "net = Net()\n",
    "print(net)\n",
    "\n",
    "# Network parameters are accessible under net.parameters()\n",
    "print(\"Network parameters\")\n",
    "params = list(net.parameters())\n",
    "for each_layer in net.parameters():\n",
    "    print(\"    {}\".format(each_layer.size()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predicting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output layer: tensor([[-0.1177,  0.0453,  0.0719, -0.0337,  0.0980,  0.0178,  0.0374,  0.0487,\n",
      "         -0.0504, -0.0719]], grad_fn=<AddmmBackward>)\n"
     ]
    }
   ],
   "source": [
    "# Making a prediction, zeroing the gradients, then backpropagating:\n",
    "\n",
    "input = torch.randn(1, 1, 32, 32)\n",
    "out = net(input)\n",
    "print(\"Output layer: {}\".format(out))\n",
    "\n",
    "net.zero_grad()   # Need to zero the gradients prior to backpropagation\n",
    "out.backward(torch.randn(1, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Computing Loss:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.5881, grad_fn=<MseLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "output = net(input)\n",
    "target = torch.randn(10)     # a dummy target, for example\n",
    "target = target.view(1, -1)  # Flatten it to the same shape as output\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "loss = criterion(output, target)\n",
    "\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the sequence of computations in a forward pass:\n",
    "\n",
    "<img src=\"images/pytorch-sample-feedforward-sequence.png\" width=\"50%\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Backpropagation:\n",
    "Now, calling `loss.backward()`, the whole computational graph is differentiated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== conv1.bias.grad before backward() ===\n",
      "tensor([0., 0., 0., 0., 0., 0.])\n",
      "=== conv1.bias.grad after backward() ===\n",
      "tensor([-0.0060, -0.0079,  0.0075,  0.0049, -0.0026,  0.0004])\n"
     ]
    }
   ],
   "source": [
    "net.zero_grad()     # zeroes the gradient buffers of all parameters\n",
    "\n",
    "print('=== conv1.bias.grad before backward() ===')\n",
    "print(net.conv1.bias.grad)\n",
    "\n",
    "loss.backward()\n",
    "\n",
    "print('=== conv1.bias.grad after backward() ===')\n",
    "print(net.conv1.bias.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using optimisers:\n",
    "All that's left to do at this point is to update the weights using an optimiser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "optimiser = optim.SGD(net.parameters(), lr=0.01)\n",
    "\n",
    "# This goes in the training loop:\n",
    "optimiser.zero_grad()\n",
    "output = net(input)\n",
    "loss = criterion(output, target)\n",
    "loss.backward()\n",
    "optimiser.step()      # step() proceeds with the update"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height: 2px;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resources:\n",
    "- <a href=\"https://medium.com/@quantumsteinke/whats-the-difference-between-a-matrix-and-a-tensor-4505fbdc576c\">Tensors vs. matrices</a>\n",
    "- <a href=\"https://github.com/kuangliu/pytorch-cifar\">High accuracy CIFAR PyTorch model</a>\n",
    "- About computational graphs in PyTorch: \n",
    "    - https://blog.paperspace.com/pytorch-101-understanding-graphs-and-automatic-differentiation/\n",
    "    - https://jdhao.github.io/2017/11/12/pytorch-computation-graph/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
